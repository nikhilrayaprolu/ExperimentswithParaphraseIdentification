{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size BATCH_SIZE]\n",
      "                             [--char-dim CHAR_DIM]\n",
      "                             [--char-hidden-size CHAR_HIDDEN_SIZE]\n",
      "                             [--data-type DATA_TYPE] [--dropout DROPOUT]\n",
      "                             [--epoch EPOCH] [--gpu GPU]\n",
      "                             [--hidden-size HIDDEN_SIZE]\n",
      "                             [--learning-rate LEARNING_RATE]\n",
      "                             [--max-sent-len MAX_SENT_LEN]\n",
      "                             [--num-perspective NUM_PERSPECTIVE]\n",
      "                             [--print-freq PRINT_FREQ] [--use-char-emb]\n",
      "                             [--word-dim WORD_DIM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1192/jupyter/kernel-b9cd9221-4379-4717-9ef0-c798df2499da.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav.appidi/new/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from model.BIMPM import BIMPM\n",
    "from model.utils import SNLI, Quora\n",
    "from test import test\n",
    "\n",
    "\n",
    "def train(args, data):\n",
    "    model = BIMPM(args, data)\n",
    "    if args.gpu > -1:\n",
    "        model.cuda(args.gpu)\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adam(parameters, lr=args.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    writer = SummaryWriter(log_dir='runs/' + args.model_time)\n",
    "\n",
    "    model.train()\n",
    "    loss, last_epoch = 0, -1\n",
    "    max_dev_acc, max_test_acc = 0, 0\n",
    "\n",
    "    iterator = data.train_iter\n",
    "    for i, batch in enumerate(iterator):\n",
    "        present_epoch = int(iterator.epoch)\n",
    "        if present_epoch == args.epoch:\n",
    "            break\n",
    "        if present_epoch > last_epoch:\n",
    "            print('epoch:', str(present_epoch + 1))\n",
    "        last_epoch = present_epoch\n",
    "\n",
    "        if args.data_type == 'SNLI':\n",
    "            s1, s2 = 'premise', 'hypothesis'\n",
    "        else:\n",
    "            s1, s2 = 'q1', 'q2'\n",
    "\n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "\n",
    "        # limit the lengths of input sentences up to max_sent_len\n",
    "        if args.max_sent_len >= 0:\n",
    "            if s1.size()[1] > args.max_sent_len:\n",
    "                s1 = s1[:, :args.max_sent_len]\n",
    "            if s2.size()[1] > args.max_sent_len:\n",
    "                s2 = s2[:, :args.max_sent_len]\n",
    "\n",
    "        kwargs = {'p': s1, 'h': s2}\n",
    "\n",
    "        if args.use_char_emb:\n",
    "            char_p = Variable(torch.LongTensor(data.characterize(s1)))\n",
    "            char_h = Variable(torch.LongTensor(data.characterize(s2)))\n",
    "\n",
    "            if args.gpu > -1:\n",
    "                char_p = char_p.cuda(args.gpu)\n",
    "                char_h = char_h.cuda(args.gpu)\n",
    "\n",
    "            kwargs['char_p'] = char_p\n",
    "            kwargs['char_h'] = char_h\n",
    "\n",
    "        pred = nn.DataParallel(model(**kwargs))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = criterion(pred, batch.label)\n",
    "        loss += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        del pred\n",
    "        del batch_loss\n",
    "        if (i + 1) % args.print_freq == 0:\n",
    "            dev_loss, dev_acc = test(model, args, data, mode='dev')\n",
    "            test_loss, test_acc = test(model, args, data)\n",
    "            c = (i + 1) // args.print_freq\n",
    "\n",
    "            writer.add_scalar('loss/train', loss, c)\n",
    "            writer.add_scalar('loss/dev', dev_loss, c)\n",
    "            writer.add_scalar('acc/dev', dev_acc, c)\n",
    "            writer.add_scalar('loss/test', test_loss, c)\n",
    "            writer.add_scalar('acc/test', test_acc, c)\n",
    "\n",
    "            print('train loss: '+ str(loss) +' / dev loss: '+ str(dev_loss) + '/ test loss:' + str(test_loss) +\n",
    "                  ' / dev acc:' + str(dev_acc) + 'test acc:' + str(test_acc))\n",
    "\n",
    "            if dev_acc > max_dev_acc:\n",
    "                max_dev_acc = dev_acc\n",
    "                max_test_acc = test_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            loss = 0\n",
    "            model.train()\n",
    "\n",
    "    writer.close()\n",
    "    print('max dev acc:'+ str(max_dev_acc) + '/ max test acc: ' + str(max_test_acc))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--char-dim', default=20, type=int)\n",
    "    parser.add_argument('--char-hidden-size', default=50, type=int)\n",
    "    parser.add_argument('--data-type', default='Quora', help='available: SNLI or Quora')\n",
    "    parser.add_argument('--dropout', default=0.1, type=float)\n",
    "    parser.add_argument('--epoch', default=10, type=int)\n",
    "    parser.add_argument('--gpu', default=0, type=int)\n",
    "    parser.add_argument('--hidden-size', default=100, type=int)\n",
    "    parser.add_argument('--learning-rate', default=0.001, type=float)\n",
    "    parser.add_argument('--max-sent-len', default=-1, type=int,\n",
    "                        help='max length of input sentences model can accept, if -1, it accepts any length')\n",
    "    parser.add_argument('--num-perspective', default=20, type=int)\n",
    "    parser.add_argument('--print-freq', default=500, type=int)\n",
    "    parser.add_argument('--use-char-emb', default=False, action='store_true')\n",
    "    parser.add_argument('--word-dim', default=300, type=int)\n",
    "    parser.add_argument('--training', default=0, type=int)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.data_type == 'SNLI':\n",
    "        print('loading SNLI data...')\n",
    "        data = SNLI(args)\n",
    "    elif args.data_type == 'Quora':\n",
    "        print('loading Quora data...')\n",
    "        data = Quora(args)\n",
    "    else:\n",
    "        raise NotImplementedError('only SNLI or Quora data is possible')\n",
    "\n",
    "    setattr(args, 'char_vocab_size', len(data.char_vocab))\n",
    "    setattr(args, 'word_vocab_size', len(data.TEXT.vocab))\n",
    "    setattr(args, 'class_size', len(data.LABEL.vocab))\n",
    "    setattr(args, 'max_word_len', data.max_word_len)\n",
    "    setattr(args, 'model_time', strftime('%H:%M:%S', gmtime()))\n",
    "\n",
    "    print('training start!')\n",
    "    best_model = train(args, data)\n",
    "\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')\n",
    "    torch.save(best_model.state_dict(), 'saved_models/BIBPM_'+args.data_type+'_'+args.model_time+'.pt')\n",
    "    print('training finished!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from model.BIMPM import BIMPM\n",
    "from model.utils import SNLI, Quora\n",
    "from test import test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Quora data...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['foo']\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch-size', default=32, type=int)\n",
    "parser.add_argument('--char-dim', default=20, type=int)\n",
    "parser.add_argument('--char-hidden-size', default=50, type=int)\n",
    "parser.add_argument('--data-type', default='Quora', help='available: SNLI or Quora')\n",
    "parser.add_argument('--dropout', default=0.1, type=float)\n",
    "parser.add_argument('--epoch', default=10, type=int)\n",
    "parser.add_argument('--gpu', default=0, type=int)\n",
    "parser.add_argument('--hidden-size', default=100, type=int)\n",
    "parser.add_argument('--learning-rate', default=0.001, type=float)\n",
    "parser.add_argument('--max-sent-len', default=-1, type=int,\n",
    "                    help='max length of input sentences model can accept, if -1, it accepts any length')\n",
    "parser.add_argument('--num-perspective', default=20, type=int)\n",
    "parser.add_argument('--print-freq', default=500, type=int)\n",
    "parser.add_argument('--use-char-emb', default=False, action='store_true')\n",
    "parser.add_argument('--word-dim', default=300, type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.data_type == 'SNLI':\n",
    "    print('loading SNLI data...')\n",
    "    data = SNLI(args)\n",
    "elif args.data_type == 'Quora':\n",
    "    print('loading Quora data...')\n",
    "    data = Quora(args)\n",
    "else:\n",
    "    raise NotImplementedError('only SNLI or Quora data is possible')\n",
    "\n",
    "setattr(args, 'char_vocab_size', len(data.char_vocab))\n",
    "setattr(args, 'word_vocab_size', len(data.TEXT.vocab))\n",
    "setattr(args, 'class_size', len(data.LABEL.vocab))\n",
    "setattr(args, 'max_word_len', data.max_word_len)\n",
    "setattr(args, 'model_time', strftime('%H:%M:%S', gmtime()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.training = 0\n",
    "model = BIMPM(args, data)\n",
    "model.load_state_dict(torch.load('saved_models/BIBPM_Quora_19:04:33.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fabe5cfcc6f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweight1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mp_w1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "weight1 = model.state_dict()['mp_w1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f9f11232e8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.cosine_similarity(torch.cat([weight1]*20,0), weight1.view(20,100,1).repeat(1,20,1).view(400,100),0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04072304128824953"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight1 = model.state_dict()['mp_w2']\n",
    "import torch.nn.functional as F\n",
    "F.cosine_similarity(torch.cat([weight1]*20,0), weight1.view(20,100,1).repeat(1,20,1).view(400,100),0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005462830512916346\n",
      "-0.009765220167142425\n",
      "0.007928040630897732\n",
      "-0.003508737254866757\n",
      "-0.005286185414220917\n",
      "-0.0020706250197882153\n",
      "0.0004789412987711809\n",
      "-0.005853073707227228\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "for i in range(1,9):\n",
    "    weight1 = model.state_dict()['mp_w'+str(i)]\n",
    "    print((F.cosine_similarity(torch.cat([weight1]*20,0),\\\n",
    "                               weight1.view(20,100,1).repeat(1,20,1).view(400,100),0).mean()*400\\\n",
    "           -F.cosine_similarity(weight1,weight1).mean()*20)/380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9932163740259714\n",
      "0.9944117102145474\n",
      "0.9960664214771039\n",
      "0.9958546397736677\n",
      "0.99487538417775\n",
      "0.9941656890852634\n",
      "0.9943433740303175\n",
      "0.9942018194943735\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(1,9):\n",
    "    weight1 = model.state_dict()['mp_w'+str(i)].numpy()\n",
    "    #np.matrix.trace(np.matmul(weight1,np.transpose(weight1))-np.identity(20))\n",
    "    norm = np.abs(weight1).sum(axis=1)\n",
    "    w2=weight1 / norm.reshape(20,1)\n",
    "    #w2=np.ones((20,20))\n",
    "    print(np.linalg.norm(np.matmul(w2,np.transpose(w2))-np.identity(20),ord=2))\n",
    "\n",
    "#F.cosine_similarity(weight1,weight1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
