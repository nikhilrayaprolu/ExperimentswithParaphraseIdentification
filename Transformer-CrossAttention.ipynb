{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'attention.transformer' has no attribute 'Constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6850c10c07aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBottleLinear\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoderLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'attention.transformer' has no attribute 'Constants'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import attention.transformer.Constants as Constants\n",
    "from attention.transformer.Modules import BottleLinear as Linear\n",
    "from attention.transformer.Layers import EncoderLayer, DecoderLayer\n",
    "\n",
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    ''' Init the sinusoid position encoding table '''\n",
    "\n",
    "    # keep dim 0 for padding token position encoding zero vector\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_pos_vec) for j in range(d_pos_vec)]\n",
    "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
    "\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "    return torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
    "\n",
    "def get_attn_padding_mask(seq_q, seq_k):\n",
    "    ''' Indicate the padding-related part to mask '''\n",
    "    assert seq_q.dim() == 2 and seq_k.dim() == 2\n",
    "    mb_size, len_q = seq_q.size()\n",
    "    mb_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(Constants.PAD).unsqueeze(1)   # bx1xsk\n",
    "    pad_attn_mask = pad_attn_mask.expand(mb_size, len_q, len_k) # bxsqxsk\n",
    "    return pad_attn_mask\n",
    "\n",
    "def get_attn_subsequent_mask(seq):\n",
    "    ''' Get an attention mask to avoid using the subsequent info.'''\n",
    "    assert seq.dim() == 2\n",
    "    attn_shape = (seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    subsequent_mask = torch.from_numpy(subsequent_mask)\n",
    "    if seq.is_cuda:\n",
    "        subsequent_mask = subsequent_mask.cuda()\n",
    "    return subsequent_mask\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' A encoder model with self attention mechanism. '''\n",
    "\n",
    "    def __init__(\n",
    "            self,data, args, n_layers=6, n_head=8, d_k=64, d_v=64,\n",
    "            d_word_vec=512, d_model=512, d_inner_hid=1024, dropout=0.1, ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.position_enc = nn.Embedding(n_position, d_word_vec, padding_idx=Constants.PAD)\n",
    "        self.position_enc.weight.data = position_encoding_init(100, d_word_vec)\n",
    "        self.word_emb = nn.Embedding(args.word_vocab_size, args.word_dim)\n",
    "        self.src_word_emb.weight.data.copy_(data.TEXT.vocab.vectors)\n",
    "        self.word_emb.weight.requires_grad = False\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, src_seq, src_pos, return_attns=False):\n",
    "        # Word embedding look up\n",
    "        enc_input = self.src_word_emb(src_seq)\n",
    "\n",
    "        # Position Encoding addition\n",
    "        enc_input += self.position_enc(src_pos)\n",
    "        if return_attns:\n",
    "            enc_slf_attns = []\n",
    "\n",
    "        enc_output = enc_input\n",
    "        enc_slf_attn_mask = get_attn_padding_mask(src_seq, src_seq)\n",
    "        for enc_layer in self.layer_stack:\n",
    "            enc_output, enc_slf_attn = enc_layer(\n",
    "                enc_output, slf_attn_mask=enc_slf_attn_mask)\n",
    "            if return_attns:\n",
    "                enc_slf_attns += [enc_slf_attn]\n",
    "\n",
    "        if return_attns:\n",
    "            return enc_output, enc_slf_attns\n",
    "        else:\n",
    "            return enc_output,\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from model.BIMPM import BIMPM\n",
    "from model.utils import SNLI, Quora\n",
    "from attention-is-all-you-need-pytorch.transformer.Models import Encoder\n",
    "\n",
    "def test(model, args, data, mode='test'):\n",
    "    if mode == 'dev':\n",
    "        iterator = iter(data.dev_iter)\n",
    "    else:\n",
    "        iterator = iter(data.test_iter)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    acc, loss, size = 0, 0, 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        if args.data_type == 'SNLI':\n",
    "            s1, s2 = 'premise', 'hypothesis'\n",
    "        else:\n",
    "            s1, s2 = 'q1', 'q2'\n",
    "\n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "        kwargs = {'p': s1, 'h': s2}\n",
    "\n",
    "        if args.use_char_emb:\n",
    "            char_p = Variable(torch.LongTensor(data.characterize(s1)))\n",
    "            char_h = Variable(torch.LongTensor(data.characterize(s2)))\n",
    "\n",
    "            if args.gpu > -1:\n",
    "                char_p = char_p.cuda()\n",
    "                char_h = char_h.cuda()\n",
    "\n",
    "            kwargs['char_p'] = char_p\n",
    "            kwargs['char_h'] = char_h\n",
    "\n",
    "        pred = model(**kwargs)\n",
    "        pred = pred.view(-1,2)\n",
    "        batch_loss = criterion(pred, batch.label)\n",
    "        loss += batch_loss.data[0]\n",
    "\n",
    "        _, pred = pred.max(dim=1)\n",
    "        acc += (pred == batch.label).sum().float()\n",
    "        size += len(pred)\n",
    "\n",
    "    acc /= size\n",
    "    acc = acc.cpu().data[0]\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def load_model(args, data):\n",
    "    model = BIMPM(args, data)\n",
    "    model.load_state_dict(torch.load(args.model_path))\n",
    "\n",
    "    if args.gpu > -1:\n",
    "        model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    r\"\"\"\n",
    "    Applies an attention mechanism on the output features from the decoder.\n",
    "    .. math::\n",
    "            \\begin{array}{ll}\n",
    "            x = context*output \\\\\n",
    "            attn = exp(x_i) / sum_j exp(x_j) \\\\\n",
    "            output = \\tanh(w * (attn * context) + b * output)\n",
    "            \\end{array}\n",
    "    Args:\n",
    "        dim(int): The number of expected features in the output\n",
    "    Inputs: output, context\n",
    "        - **output** (batch, output_len, dimensions): tensor containing the output features from the decoder.\n",
    "        - **context** (batch, input_len, dimensions): tensor containing features of the encoded input sequence.\n",
    "    Outputs: output, attn\n",
    "        - **output** (batch, output_len, dimensions): tensor containing the attended output features from the decoder.\n",
    "        - **attn** (batch, output_len, input_len): tensor containing attention weights.\n",
    "    Attributes:\n",
    "        linear_out (torch.nn.Linear): applies a linear transformation to the incoming data: :math:`y = Ax + b`.\n",
    "        mask (torch.Tensor, optional): applies a :math:`-inf` to the indices specified in the `Tensor`.\n",
    "    Examples::\n",
    "         >>> attention = seq2seq.models.Attention(256)\n",
    "         >>> context = Variable(torch.randn(5, 3, 256))\n",
    "         >>> output = Variable(torch.randn(5, 5, 256))\n",
    "         >>> output, attn = attention(output, context)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear_out = nn.Linear(dim*2, dim)\n",
    "        self.mask = None\n",
    "\n",
    "    def set_mask(self, mask):\n",
    "        \"\"\"\n",
    "        Sets indices to be masked\n",
    "        Args:\n",
    "            mask (torch.Tensor): tensor containing indices to be masked\n",
    "        \"\"\"\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, output, context):\n",
    "        batch_size = output.size(0)\n",
    "        hidden_size = output.size(2)\n",
    "        input_size = context.size(1)\n",
    "        # (batch, out_len, dim) * (batch, in_len, dim) -> (batch, out_len, in_len)\n",
    "        attn = torch.bmm(output, context.transpose(1, 2))\n",
    "        if self.mask is not None:\n",
    "            attn.data.masked_fill_(self.mask, -float('inf'))\n",
    "        attn = F.softmax(attn.view(-1, input_size)).view(batch_size, -1, input_size)\n",
    "\n",
    "        # (batch, out_len, in_len) * (batch, in_len, dim) -> (batch, out_len, dim)\n",
    "        mix = torch.bmm(attn, context)\n",
    "\n",
    "        # concat -> (batch, out_len, 2*dim)\n",
    "        combined = torch.cat((mix, output), dim=2)\n",
    "        # output -> (batch, out_len, dim)\n",
    "        output = F.tanh(self.linear_out(combined.view(-1, 2 * hidden_size))).view(batch_size, -1, hidden_size)\n",
    "\n",
    "        return output, attn\n",
    "    \n",
    "class Siamese(nn.Module):\n",
    "    def __init__(self, args, data, use_attention = False):\n",
    "        super(Siamese, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.d = self.args.word_dim + int(self.args.use_char_emb) * self.args.char_hidden_size\n",
    "        self.l = self.args.num_perspective\n",
    "\n",
    "        # ----- Word Representation Layer -----\n",
    "        self.char_emb = nn.Embedding(args.char_vocab_size, args.char_dim, padding_idx=0)\n",
    "        \n",
    "        self.word_emb = nn.Embedding(args.word_vocab_size, args.word_dim)\n",
    "        # initialize word embedding with GloVe\n",
    "        self.word_emb.weight.data.copy_(data.TEXT.vocab.vectors)\n",
    "        # no fine-tuning for word vectors\n",
    "        self.word_emb.weight.requires_grad = False\n",
    "        self.trainingtype = args.training\n",
    "        self.use_attention = use_attention\n",
    "        if self.use_attention:\n",
    "            self.attention = Attention(self.args.hidden_size*2)\n",
    "        \n",
    "        self.char_LSTM = nn.LSTM(\n",
    "            input_size=self.args.char_dim,\n",
    "            hidden_size=self.args.char_hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=False,\n",
    "            batch_first=True)\n",
    "\n",
    "        # ----- Context Representation Layer -----\n",
    "        self.context_LSTM = nn.LSTM(\n",
    "            input_size=self.d,\n",
    "            hidden_size=self.args.hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.aggregation_LSTM = nn.LSTM(\n",
    "            input_size=self.args.hidden_size*2,\n",
    "            hidden_size=self.args.hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = Encoder(\n",
    "            data, args)\n",
    "        \n",
    "        self.Ws = nn.Parameter(torch.rand(self.args.hidden_size*2,self.args.hidden_size*2))\n",
    "        self.Us = nn.Parameter(torch.rand(self.args.hidden_size*2,self.args.hidden_size*2))\n",
    "        self.bs = nn.Parameter(torch.rand(self.args.hidden_size*2))\n",
    "        \n",
    "        # ----- Prediction Layer -----\n",
    "        self.pred_fc1 = nn.Linear(self.args.hidden_size * 4, self.args.hidden_size * 2)\n",
    "        self.pred_fc2 = nn.Linear(self.args.hidden_size * 2, self.args.class_size)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # ----- Word Representation Layer -----\n",
    "        nn.init.uniform(self.char_emb.weight, -0.005, 0.005)\n",
    "        # zero vectors for padding\n",
    "        self.char_emb.weight.data[0].fill_(0)\n",
    "\n",
    "        # <unk> vectors is randomly initialized\n",
    "        nn.init.uniform(self.word_emb.weight.data[0], -0.1, 0.1)\n",
    "\n",
    "        nn.init.kaiming_normal(self.char_LSTM.weight_ih_l0)\n",
    "        nn.init.constant(self.char_LSTM.bias_ih_l0, val=0)\n",
    "        nn.init.orthogonal(self.char_LSTM.weight_hh_l0)\n",
    "        nn.init.constant(self.char_LSTM.bias_hh_l0, val=0)\n",
    "\n",
    "        # ----- Context Representation Layer -----\n",
    "        nn.init.kaiming_normal(self.context_LSTM.weight_ih_l0)\n",
    "        nn.init.constant(self.context_LSTM.bias_ih_l0, val=0)\n",
    "        nn.init.orthogonal(self.context_LSTM.weight_hh_l0)\n",
    "        nn.init.constant(self.context_LSTM.bias_hh_l0, val=0)\n",
    "\n",
    "        nn.init.kaiming_normal(self.context_LSTM.weight_ih_l0_reverse)\n",
    "        nn.init.constant(self.context_LSTM.bias_ih_l0_reverse, val=0)\n",
    "        nn.init.orthogonal(self.context_LSTM.weight_hh_l0_reverse)\n",
    "        nn.init.constant(self.context_LSTM.bias_hh_l0_reverse, val=0)\n",
    "\n",
    "        # ----- Prediction Layer ----\n",
    "        nn.init.uniform(self.pred_fc1.weight, -0.005, 0.005)\n",
    "        nn.init.constant(self.pred_fc1.bias, val=0)\n",
    "\n",
    "        nn.init.uniform(self.pred_fc2.weight, -0.005, 0.005)\n",
    "        nn.init.constant(self.pred_fc2.bias, val=0)\n",
    "\n",
    "    def dropout(self, v):\n",
    "        return F.dropout(v, p=self.args.dropout, training=self.training)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        p = self.word_emb(kwargs['p'])\n",
    "        h = self.word_emb(kwargs['h'])\n",
    "        print(p.shape, h.shape)\n",
    "        p_pos = torch.arange(0,p.shape[1]).view(1,-1).expand(p.shape[0],p.shape[1])\n",
    "        h_pos = torch.arange(0,h.shape[1]).view(1,-1).expand(h.shape[0],h.shape[1])\n",
    "        p_enc_output, *_ = self.encoder(p, p_pos)\n",
    "        h_enc_output, *_ = self.encoder(h, h_pos)\n",
    "        print(p_enc_output.shape, h_enc_output.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        # ----- Prediction Layer -----\n",
    "        #x = F.tanh(self.pred_fc1(x))\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.pred_fc2(x)\n",
    "        #print(x.shape)\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loading Quora data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aef2bc81a0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-aef2bc81a0ad>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Quora'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading Quora data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'only SNLI or Quora data is possible'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/BIMPM-pytorch/model/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'q1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'q2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                     ('id', self.RAW)])\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'840B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         train_data = None if train is None else cls(\n\u001b[0;32m---> 72\u001b[0;31m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[1;32m     73\u001b[0m         val_data = None if validation is None else cls(\n\u001b[1;32m     74\u001b[0m             os.path.join(path, validation), **kwargs)\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, format, fields, skip_header, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_example\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromJSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_example\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromJSON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torchtext/data/example.py\u001b[0m in \u001b[0;36mfromTSV\u001b[0;34m(cls, data, fields)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfromTSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new/lib/python3.5/site-packages/torchtext/data/example.py\u001b[0m in \u001b[0;36mfromlist\u001b[0;34m(cls, data, fields)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from model.BIMPM import BIMPM\n",
    "from model.utils import SNLI, Quora\n",
    "\n",
    "\n",
    "\n",
    "def train(args, data):\n",
    "    model = (Siamese(args, data,use_attention = True))\n",
    "    if args.gpu > -1:\n",
    "        model.cuda()\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adam(parameters, lr=args.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    writer = SummaryWriter(log_dir='runs/' + args.model_time)\n",
    "\n",
    "    model.train()\n",
    "    loss, last_epoch = 0, -1\n",
    "    max_dev_acc, max_test_acc = 0, 0\n",
    "\n",
    "    iterator = data.train_iter\n",
    "    for i, batch in enumerate(iterator):\n",
    "        present_epoch = int(iterator.epoch)\n",
    "        if present_epoch == args.epoch:\n",
    "            break\n",
    "        if present_epoch > last_epoch:\n",
    "            print('epoch:', str(present_epoch + 1))\n",
    "        last_epoch = present_epoch\n",
    "\n",
    "        if args.data_type == 'SNLI':\n",
    "            s1, s2 = 'premise', 'hypothesis'\n",
    "        else:\n",
    "            s1, s2 = 'q1', 'q2'\n",
    "\n",
    "        s1, s2 = getattr(batch, s1), getattr(batch, s2)\n",
    "        print(s1.shape, s2.shape)\n",
    "\n",
    "        # limit the lengths of input sentences up to max_sent_len\n",
    "        if args.max_sent_len >= 0:\n",
    "            if s1.size()[1] > args.max_sent_len:\n",
    "                s1 = s1[:, :args.max_sent_len]\n",
    "            if s2.size()[1] > args.max_sent_len:\n",
    "                s2 = s2[:, :args.max_sent_len]\n",
    "\n",
    "        kwargs = {'p': s1, 'h': s2}\n",
    "\n",
    "        if args.use_char_emb:\n",
    "            char_p = Variable(torch.LongTensor(data.characterize(s1)))\n",
    "            char_h = Variable(torch.LongTensor(data.characterize(s2)))\n",
    "\n",
    "            if args.gpu > -1:\n",
    "                char_p = char_p.cuda()\n",
    "                char_h = char_h.cuda()\n",
    "\n",
    "            kwargs['char_p'] = char_p\n",
    "            kwargs['char_h'] = char_h\n",
    "\n",
    "        pred = (model(**kwargs))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #print(pred.shape, batch.label.shape)\n",
    "        batch_loss = criterion(pred.view(-1,2), batch.label)\n",
    "        loss += batch_loss.data[0]\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        del pred\n",
    "        del batch_loss\n",
    "        if (i + 1) % args.print_freq == 0:\n",
    "            dev_loss, dev_acc = test(model, args, data, mode='dev')\n",
    "            test_loss, test_acc = test(model, args, data)\n",
    "            c = (i + 1) // args.print_freq\n",
    "\n",
    "            writer.add_scalar('loss/train', loss, c)\n",
    "            writer.add_scalar('loss/dev', dev_loss, c)\n",
    "            writer.add_scalar('acc/dev', dev_acc, c)\n",
    "            writer.add_scalar('loss/test', test_loss, c)\n",
    "            writer.add_scalar('acc/test', test_acc, c)\n",
    "\n",
    "            print('train loss: '+ str(loss) +' / dev loss: '+ str(dev_loss) + '/ test loss:' + str(test_loss) +\n",
    "                  ' / dev acc:' + str(dev_acc) + 'test acc:' + str(test_acc))\n",
    "\n",
    "            if dev_acc > max_dev_acc:\n",
    "                max_dev_acc = dev_acc\n",
    "                max_test_acc = test_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            loss = 0\n",
    "            model.train()\n",
    "\n",
    "    writer.close()\n",
    "    print('max dev acc:'+ str(max_dev_acc) + '/ max test acc: ' + str(max_test_acc))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    import sys\n",
    "    sys.argv = ['foo']\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--batch-size', default=128, type=int)\n",
    "    parser.add_argument('--char-dim', default=20, type=int)\n",
    "    parser.add_argument('--char-hidden-size', default=50, type=int)\n",
    "    parser.add_argument('--data-type', default='Quora', help='available: SNLI or Quora')\n",
    "    parser.add_argument('--dropout', default=0.1, type=float)\n",
    "    parser.add_argument('--epoch', default=15, type=int)\n",
    "    parser.add_argument('--gpu', default=0, type=int)\n",
    "    parser.add_argument('--hidden-size', default=100, type=int)\n",
    "    parser.add_argument('--learning-rate', default=0.001, type=float)\n",
    "    parser.add_argument('--max-sent-len', default=-1, type=int,\n",
    "                        help='max length of input sentences model can accept, if -1, it accepts any length')\n",
    "    parser.add_argument('--num-perspective', default=20, type=int)\n",
    "    parser.add_argument('--print-freq', default=500, type=int)\n",
    "    parser.add_argument('--use-char-emb', default=False, action='store_true')\n",
    "    parser.add_argument('--word-dim', default=300, type=int)\n",
    "    parser.add_argument('--training', default=0, type=int)\n",
    "    args = parser.parse_args()\n",
    "    print(args.training)\n",
    "    if args.data_type == 'SNLI':\n",
    "        print('loading SNLI data...')\n",
    "        data = SNLI(args)\n",
    "    elif args.data_type == 'Quora':\n",
    "        print('loading Quora data...')\n",
    "        data = Quora(args)\n",
    "    else:\n",
    "        raise NotImplementedError('only SNLI or Quora data is possible')\n",
    "\n",
    "    setattr(args, 'char_vocab_size', len(data.char_vocab))\n",
    "    setattr(args, 'word_vocab_size', len(data.TEXT.vocab))\n",
    "    setattr(args, 'class_size', len(data.LABEL.vocab))\n",
    "    setattr(args, 'max_word_len', data.max_word_len)\n",
    "    setattr(args, 'model_time', strftime('%H:%M:%S', gmtime()))\n",
    "\n",
    "    print('training start!')\n",
    "    best_model = train(args, data)\n",
    "\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')\n",
    "    torch.save(best_model.state_dict(), 'saved_models/BIBPM_'+args.data_type+'_'+args.model_time+'train'+args.training+'.pt')\n",
    "    print('training finished!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, 1, bidirectional=True)\n",
    "input = Variable(torch.randn(5, 3, 10))\n",
    "h0 = Variable(torch.randn(2, 3, 20))\n",
    "c0 = Variable(torch.randn(2, 3, 20))\n",
    "output, hn = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0262 -0.0300  0.1385  0.0517 -0.1187 -0.1581  0.0058 -0.0630 -0.0708\n",
       "   0.0431  0.0000 -0.1865  0.2206  0.1467 -0.2882 -0.0504 -0.3230 -0.0736\n",
       "   0.1322 -0.0603  0.1803  0.1033 -0.2160 -0.1069 -0.0303  0.1110  0.0982\n",
       " \n",
       " Columns 9 to 17 \n",
       "    0.1379 -0.0159 -0.0569  0.1671 -0.1168  0.1358 -0.0823  0.0798  0.0735\n",
       "   0.1638  0.1187 -0.0314 -0.1135 -0.1871  0.0551  0.1918 -0.1770 -0.1505\n",
       "  -0.0077  0.1058 -0.0803  0.1280 -0.0647 -0.0149  0.1065 -0.1494  0.1058\n",
       " \n",
       " Columns 18 to 19 \n",
       "    0.0836 -0.0075\n",
       "  -0.0716 -0.1395\n",
       "   0.1533  0.0331\n",
       " \n",
       " (1 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0218  0.1405  0.0528  0.0870  0.2355  0.0391  0.1179 -0.1470  0.1026\n",
       "  -0.1145 -0.0303 -0.1846 -0.0444 -0.2343  0.0695  0.0592 -0.0462  0.0413\n",
       "   0.1245  0.1497  0.0318 -0.0747  0.1270  0.1806 -0.0454 -0.1718  0.1462\n",
       " \n",
       " Columns 9 to 17 \n",
       "   -0.0491  0.0722  0.0430  0.1969 -0.0574 -0.0376  0.1289 -0.0570  0.0927\n",
       "  -0.0145  0.0295 -0.0678  0.0056  0.1946  0.1184  0.1774 -0.1404 -0.0458\n",
       "  -0.1120 -0.0548 -0.0249  0.1601  0.1792  0.1098 -0.2562  0.0462 -0.0287\n",
       " \n",
       " Columns 18 to 19 \n",
       "   -0.1299  0.0748\n",
       "  -0.0381 -0.2646\n",
       "  -0.2266 -0.0379\n",
       " [torch.FloatTensor of size 2x3x20], Variable containing:\n",
       " (0 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0727 -0.0482  0.2978  0.0970 -0.2090 -0.3533  0.0137 -0.1320 -0.1972\n",
       "   0.0912  0.0000 -0.3299  0.5086  0.2623 -0.4963 -0.1592 -0.5498 -0.1705\n",
       "   0.4063 -0.1658  0.3195  0.2035 -0.4086 -0.2152 -0.0672  0.2179  0.2869\n",
       " \n",
       " Columns 9 to 17 \n",
       "    0.2457 -0.0312 -0.0978  0.2423 -0.2201  0.2292 -0.1269  0.3032  0.1604\n",
       "   0.3014  0.2765 -0.0835 -0.1674 -0.3090  0.1504  0.3951 -0.3920 -0.3827\n",
       "  -0.0155  0.3424 -0.2246  0.2083 -0.1162 -0.0298  0.2375 -0.3460  0.1651\n",
       " \n",
       " Columns 18 to 19 \n",
       "    0.1906 -0.0168\n",
       "  -0.1533 -0.2548\n",
       "   0.3252  0.1103\n",
       " \n",
       " (1 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0631  0.2817  0.1168  0.2178  0.3444  0.0571  0.2109 -0.2296  0.2696\n",
       "  -0.1884 -0.0529 -0.3766 -0.0668 -0.3665  0.1372  0.1446 -0.0888  0.1378\n",
       "   0.2853  0.3587  0.0653 -0.1531  0.2440  0.3026 -0.0799 -0.3610  0.3513\n",
       " \n",
       " Columns 9 to 17 \n",
       "   -0.1209  0.1599  0.1192  0.3646 -0.0949 -0.0617  0.2403 -0.2089  0.1627\n",
       "  -0.0267  0.0678 -0.1334  0.0103  0.3997  0.2439  0.3168 -0.2974 -0.0745\n",
       "  -0.2430 -0.1239 -0.0604  0.3928  0.3393  0.2123 -0.5639  0.1221 -0.0612\n",
       " \n",
       " Columns 18 to 19 \n",
       "   -0.2121  0.1477\n",
       "  -0.0695 -0.3737\n",
       "  -0.4132 -0.0618\n",
       " [torch.FloatTensor of size 2x3x20])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'attention.transformer' has no attribute 'Constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ed7d676356d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/BIMPM-pytorch/attention/transformer/Models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBottleLinear\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoderLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'attention.transformer' has no attribute 'Constants'"
     ]
    }
   ],
   "source": [
    "import attention.transformer.Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'attention.transformer' has no attribute 'Constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3daa9b7acf6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'attention.transformer' has no attribute 'Constants'"
     ]
    }
   ],
   "source": [
    "import attention.transformer.Constants as constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PAD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1f67a8459dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPAD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PAD' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
